# ThisCapstone-Project-1
 	Marketing is one of the most important factors in any business, targeting right customers is a main key in marketing and can save time and money . Credit companies like other businesses should find customers to sell offers, therefore they have to target customers. Some companies send credit offers to people only based on bank and credit history of people but it is not the only factor, by knowing some other factors and get some sense of type of  clients and how customers spend their credit cards, companies will be able to target customers more sufficient.
	My goal of this project is grouping customers based on their behavior on spending credit cards like balance, payments, purchases, cash advance, minimum payment and credit-limit and find a behavioral trend in each group so companies will be estimate type of customers and send the right offers and get better acceptances.
 	The data that is going to be used for this analysis; CC GENERAL.csv, which is taken from Kaggle and included  credit card holders' informations.
The analysis is planning to be delivered in papers which included plots, jupyter notebook with cods and final report which included presentation slides. 
In order to start off my project, I should look deeper in it and get its insight so print examine it and found out it is a clean data set which does not any specific wrangling process but some that I mention in the following paragraph.
	So a first step I should get information about my data set which is done by (df.info) and then I realize that there are some missing values(one in CREDIT_LIMIT and 313 values in MINIMUM_PAYMENTS column) so I did backfill to deal with missing values.
	Also in  order to figure out the outliers I should do  Box.plot but before that I looked at describe of the data set and realized that there are variables with huge number with makes the box.plot so shrink and unclear so I put them in a separated data frame  and did log.transform to get a clearer plot and it shows some outliers so I applies IRQ methodology in the dataset to remove it. I am not sure that I want to work on my data set with or without the outliers, it depends on model because removing outliers may hurt the model.
	So, now it is the time to talk to our data set and see what it is telling us, in order to do it, we should visualize it and see the features in plots therefore we be able to tell its story. I did some process which is explained below:
	By looking at pair plot that includes scatter and bar, it gives me a correlation between ONEOFF_PURCHASES and PURCHASES , PURCHASES and INSTAL- MENTS_PURCHASES they both have positive correlation which it is obvious since they both are purchase. But the trend in other variables looks like groups, looks like some observations behave in a same way that makes them separated therefore can be considered as segments for customers and finding some interesting values in each segment.
	To make more clear what I realize, I did scatter plots separately for BALANCE and CREDIT_LIMIT, BALANCE, PAYMENTS and CREDIT_LIMIT and PURCHASES to show some segments which the slides of scatter plots are attached.

	As I go deeper to my data set, I realize some things that may affect the model that I am  trying to predict the data set with, so I should to explore the numbers in variables and how variant they are and their range and scale. As df.describe() shows the variables: ('CASH_ADVANCE', 'BALANCE', 'PURCHASES','ONEOFF_PURCHASES',
          'INSTALLMENTS_PURCHASES', 'CASH_ADVANCE_TRX', 'PURCHASES_TRX','CREDIT_LIMIT','PAYMENTS','MINIMUM_PAYMENTS','PRC_FULL_PAYMENT') have high variance, so I scale them by sklearn preprocessing. As I realize some trend and correlation in some features through the pair plot, I need to see  numbers of the correlation therefore Pearson method is a good one to do it.  (PURCHASES_FREQUENCY, PURCHASES_INSTALLMENTS_FREQUEENCY. PURCHASES, ONEOFF_PURCHASES. CASH_ADVANCE_FREQUENCY, CASH_ADVANCE_TRX) have high rate as I expected.
I should put more attention to variables with strong correlation. I may need to decorrelate or remove them based on the model that I will use for my data.


Now my data set is ready to get a model and analyze.
	My data set is not labeled , there is no target value therefore I should use unsupervised techniques.
I should make groups and clusters from my data set and analyze the observations in each group to get some same values and trend and be able to interpret them.
After doing some appropriate techniques like KMeans, hierarchical and mean-shift and talking to my mentor I decided to use KMeans which is the most popular one for unsupervised data set. And also by comparing the result of each clustering and plotting the data set in two dimension by using PCA, the overlaps from KMeans was the least one.
	As I mentioned the outliers and correlation in the some features, I did not remove them, since removing them hurt clustering.
Searching the right number of k for KMeans clustering is the main factor , so I used elbow and silhouette to find the best k and then try it on my cluster.
I used the array of centroids of cluster to interpret the observation in each cluster.
